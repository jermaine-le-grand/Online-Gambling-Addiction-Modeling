{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "9ROWmJANBjvH",
    "outputId": "11a9acfe-3aa9-4857-9491-93671896cf10"
   },
   "outputs": [],
   "source": [
    "# Dependencies for Google Colab and Libraries required for processes\n",
    "!pip install optuna\n",
    "!pip install shap --quiet\n",
    "!pip install langchain together sentence-transformers faiss-cpu\n",
    "!pip install langchain langchain-community together\n",
    "\n",
    "import os\n",
    "import re\n",
    "import io\n",
    "import glob\n",
    "import time\n",
    "import random\n",
    "import shap\n",
    "import optuna\n",
    "import faiss\n",
    "import logging\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from collections import Counter\n",
    "from google.colab import files\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import defaultdict\n",
    "from matplotlib_venn import venn2\n",
    "from matplotlib_venn import venn3\n",
    "from functools import reduce\n",
    "from sklearn.metrics import classification_report, roc_auc_score, accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from xgboost import XGBClassifier\n",
    "from langchain_community.llms import Together\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.schema.document import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wQYYDxBbMb7D"
   },
   "outputs": [],
   "source": [
    "# === GLOBAL RANDOM SEEDS FOR LATER USE ===\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "\n",
    "# === Generate 10 randomized but reproducible seeds ===\n",
    "random_seeds = random.sample(range(1, 100000), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 229
    },
    "collapsed": true,
    "id": "YU2_snlNBtiM",
    "outputId": "5a90d1b6-ddc5-4486-e869-a82320ebbd99"
   },
   "outputs": [],
   "source": [
    "# === UPLOAD & FILTER ===\n",
    "\n",
    "print(\" Upload your 2019–2020 filtered CSVs:\")\n",
    "uploaded = files.upload()  # Upload files first\n",
    "\n",
    "# === DEFINE FILE NAMES YOU JUST UPLOADED ===\n",
    "# Make sure these match your actual file names (case-sensitive)\n",
    "file_paths = {\n",
    "    'demographics': 'SecondSeshData1Demographics_filtered_2019_2020.csv',\n",
    "    'cash_games': 'SecondSeshData2CashGames_filtered_2019_2020.csv',\n",
    "    'tournaments': 'SecondSeshData3Tournaments_filtered_2019_2020.csv',\n",
    "    'deposits': 'SecondSeshData4Deposits_filtered_2019_2020.csv',\n",
    "    'withdrawals': 'SecondSeshData5Withdrawals_filtered_2019_2020.csv'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "24p3Xe75IiPN"
   },
   "outputs": [],
   "source": [
    "# === Aggregation Function ===\n",
    "def aggregate_behavior(df, prefix, sum_cols=[], mean_cols=[], count_col=None, date_col=None):\n",
    "    print(f\"Running aggregation for: {prefix}\")\n",
    "    print(\" Original columns in dataset:\", df.columns.tolist())\n",
    "    if date_col:\n",
    "        df[date_col] = pd.to_datetime(df[date_col], errors='coerce')\n",
    "        df['YearMonth'] = df[date_col].dt.to_period('M')\n",
    "\n",
    "    if count_col and 'YearMonth' in df:\n",
    "        monthly_max = df.groupby(['UserID', 'YearMonth'])[count_col].sum().reset_index()\n",
    "        max_monthly = monthly_max.groupby('UserID')[count_col].max().reset_index()\n",
    "        max_monthly.rename(columns={count_col: f'{prefix}_{count_col}_max_month'}, inplace=True)\n",
    "    else:\n",
    "        max_monthly = None\n",
    "\n",
    "    agg_dict = {}\n",
    "    for col in sum_cols:\n",
    "        if col in df.columns:\n",
    "            print(f\" Including SUM for '{col}'\")\n",
    "            agg_dict[col] = ['sum']\n",
    "    for col in mean_cols:\n",
    "        if col in df.columns:\n",
    "            print(f\" Including MEAN for '{col}'\")\n",
    "            agg_dict[col] = ['mean']\n",
    "    if count_col and count_col in df.columns:\n",
    "        print(f\" Including SUM and COUNT for '{count_col}'\")\n",
    "        agg_dict[count_col] = ['sum', 'count']\n",
    "    if 'YearMonth' in df.columns:\n",
    "        print(\" Including 'YearMonth' nunique\")\n",
    "        agg_dict['YearMonth'] = 'nunique'\n",
    "\n",
    "    if not agg_dict:\n",
    "        return pd.DataFrame(columns=['UserID'])\n",
    "\n",
    "    agg = df.groupby('UserID').agg(agg_dict)\n",
    "    agg.columns = [f\"{prefix}_{col[0]}_{col[1]}\" if isinstance(col, tuple) else f\"{prefix}_{col}\" for col in agg.columns]\n",
    "    agg.reset_index(inplace=True)\n",
    "\n",
    "    if max_monthly is not None:\n",
    "        agg = pd.merge(agg, max_monthly, on='UserID', how='left')\n",
    "\n",
    "    print(\" Aggregated columns:\", agg.columns.tolist())\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "lWjaUQ1jY1Pl",
    "outputId": "a5910f89-c1c3-4b30-9a5a-9737cf5cb568"
   },
   "outputs": [],
   "source": [
    "# === Load and Aggregate data ===\n",
    "aggregated_dfs = []\n",
    "demographics = None\n",
    "\n",
    "for key, path in file_paths.items():\n",
    "    try:\n",
    "        df = pd.read_csv(path)\n",
    "    except FileNotFoundError:\n",
    "        continue\n",
    "\n",
    "    if key == 'demographics':\n",
    "        demographics = df\n",
    "        continue\n",
    "\n",
    "    if key == 'cash_games':\n",
    "      cash_games_df = df.copy()  # 🔹 SAVE IT HERE\n",
    "      agg = aggregate_behavior(df, 'engage_cash', ['StakesC', 'WinningsC'], ['StakesC', 'WinningsC'], 'Windows', 'Date')\n",
    "    elif key == 'tournaments':\n",
    "        tournaments_df = df.copy()\n",
    "        agg = aggregate_behavior(df, 'engage_tourn', ['StakesT', 'WinningsT'], ['StakesT', 'WinningsT'], 'Trnmnts', 'Date')\n",
    "    elif key == 'deposits':\n",
    "        deposits_df = df.copy()\n",
    "        agg = aggregate_behavior(df, 'monetary_deposit', ['Amount'], [], 'Amount', 'SummaryDate')\n",
    "    elif key == 'withdrawals':\n",
    "        withdrawals_df = df.copy()\n",
    "        agg = aggregate_behavior(df, 'monetary_withdraw', ['Amount'], [], 'Amount', 'SummaryDate')\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "    if not agg.empty:\n",
    "        aggregated_dfs.append(agg)\n",
    "\n",
    "print(\"Aggregated tournament columns:\", agg.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GtyqQXRNcZrh"
   },
   "outputs": [],
   "source": [
    "# === Merge and Label data ===\n",
    "if aggregated_dfs:\n",
    "    summary_df = reduce(lambda left, right: pd.merge(left, right, on='UserID', how='outer'), aggregated_dfs)\n",
    "    summary_df.fillna(0, inplace=True)\n",
    "\n",
    "    # === PERCENTILE-BASED THRESHOLDS (90th percentile for inclusivity) ===\n",
    "    cash_threshold = summary_df['engage_cash_Windows_sum'].quantile(0.90)\n",
    "    cash_burst_threshold = summary_df['engage_cash_Windows_max_month'].quantile(0.90)\n",
    "    tourn_count_threshold = summary_df['engage_tourn_Trnmnts_sum'].quantile(0.90)\n",
    "    tourn_burst_threshold = summary_df['engage_tourn_Trnmnts_max_month'].quantile(0.90)\n",
    "    tourn_stake_threshold = summary_df['engage_tourn_StakesT_mean'].quantile(0.90)\n",
    "    deposit_sum_threshold = summary_df['monetary_deposit_Amount_sum'].quantile(0.90)\n",
    "    deposit_count_threshold = summary_df['monetary_deposit_Amount_count'].quantile(0.90)\n",
    "\n",
    "    # === COMPONENT FLAGS ===\n",
    "    summary_df['addicted_cash'] = (\n",
    "        (summary_df['engage_cash_Windows_sum'] > cash_threshold) |\n",
    "        (summary_df['engage_cash_Windows_max_month'] > cash_burst_threshold)\n",
    "    )\n",
    "\n",
    "    summary_df['addicted_tourn'] = (\n",
    "        (summary_df['engage_tourn_Trnmnts_sum'] > tourn_count_threshold) |\n",
    "        (summary_df['engage_tourn_Trnmnts_max_month'] > tourn_burst_threshold) |\n",
    "        (summary_df['engage_tourn_StakesT_mean'] > tourn_stake_threshold)\n",
    "    )\n",
    "\n",
    "    # === FINAL LABEL: IS ADDICTED ===\n",
    "    summary_df['is_addicted'] = (\n",
    "        summary_df['addicted_cash'] |\n",
    "        summary_df['addicted_tourn'] |\n",
    "        (summary_df['monetary_deposit_Amount_sum'] > deposit_sum_threshold) |\n",
    "        (summary_df['monetary_deposit_Amount_count'] > deposit_count_threshold)\n",
    "    ).astype(int)\n",
    "\n",
    "else:\n",
    "    summary_df = pd.DataFrame(columns=['UserID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "collapsed": true,
    "id": "8DbhGpLkitf5",
    "outputId": "5e532cff-18d3-4d84-f16d-46b1ab8b87f6"
   },
   "outputs": [],
   "source": [
    "# IN-BETWEEN STEP\n",
    "# 7 manually selected heuristic features (from your old logic)\n",
    "feature_cols = [\n",
    "    'engage_cash_Windows_sum',\n",
    "    'engage_cash_Windows_max_month',\n",
    "    'engage_tourn_Trnmnts_sum',\n",
    "    'engage_tourn_Trnmnts_max_month',\n",
    "    'engage_tourn_StakesT_mean',\n",
    "    'monetary_deposit_Amount_sum',\n",
    "    'monetary_deposit_Amount_count'\n",
    "]\n",
    "\n",
    "# Group and compute mean values for each feature by addiction label\n",
    "grouped_means = summary_df.groupby('is_addicted')[feature_cols].mean().T\n",
    "grouped_means.columns = ['Not Addicted', 'Addicted']\n",
    "\n",
    "# Show the table (optional)\n",
    "display(grouped_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 715
    },
    "id": "MP9kWrBncc_C",
    "outputId": "2e3eb6e0-c23e-4c24-a778-37e9bc06bd2a"
   },
   "outputs": [],
   "source": [
    "# === Train XGBoost Model ===\n",
    "# === NO RANDOM SEED USED HERE, IT IS SET TO 42\n",
    "if not summary_df.empty and 'is_addicted' in summary_df.columns:\n",
    "    X = summary_df.drop(columns=['UserID', 'is_addicted'])\n",
    "    y = summary_df['is_addicted']\n",
    "\n",
    "    if len(X) > 0:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "        model = XGBClassifier(\n",
    "            use_label_encoder=False,\n",
    "            eval_metric='logloss',\n",
    "            n_estimators=25,\n",
    "            max_depth=3,\n",
    "            subsample=0.5,\n",
    "            colsample_bytree=0.5,\n",
    "            verbosity=0\n",
    "        )\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        y_pred = model.predict(X_test)\n",
    "        print(\"\\n\\U0001F4CA Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "        print(\"\\U0001F4C8 AUC Score:\", round(roc_auc_score(y_test, model.predict_proba(X_test)[:, 1]), 4))\n",
    "\n",
    "        # Feature importance\n",
    "        plt.figure(figsize=(8, 5))\n",
    "        pd.Series(model.feature_importances_, index=X.columns).sort_values().plot(kind='barh')\n",
    "        plt.title(\"Feature Importance (XGBoost)\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\" Not enough usable training data.\")\n",
    "else:\n",
    "    print(\" Summary dataframe is empty or missing target label.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 785
    },
    "id": "3917Co1nqKb-",
    "outputId": "78909142-c2f4-41f5-cf8a-4b387169b1ef"
   },
   "outputs": [],
   "source": [
    "# === ML: Filter Features and Remove Label Leakage ===\n",
    "# === WE ALSO INCLUDED A RANDOM SEED NUMBER INSTEAD OF DEFAULTING TO 42 ===\n",
    "# === ONLY USING 1 RANDOM SEED HERE ===\n",
    "leakage_cols = [\n",
    "    'engage_cash_Windows', 'engage_cash_Windows_sum', 'engage_cash_Windows_max_month',\n",
    "    'engage_tourn_Trnmnts', 'engage_tourn_Trnmnts_sum', 'engage_tourn_Trnmnts_max_month',\n",
    "    'engage_tourn_StakesT_mean', 'monetary_deposit_Amount',\n",
    "    'monetary_deposit_Amount_sum', 'monetary_deposit_Amount_count'\n",
    "]\n",
    "\n",
    "feature_cols = [col for col in summary_df.columns if col not in leakage_cols + [\n",
    "    'UserID', 'is_addicted', 'addicted_cash', 'addicted_tourn', 'addiction_type'\n",
    "]]\n",
    "\n",
    "X = summary_df[feature_cols]\n",
    "y = summary_df['is_addicted']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=SEED)\n",
    "\n",
    "model = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=SEED)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "y_prob = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"AUC Score:\", roc_auc_score(y_test, y_prob))\n",
    "\n",
    "# Feature importance\n",
    "plt.figure(figsize=(8, 5))\n",
    "pd.Series(model.feature_importances_, index=X.columns).sort_values().plot(kind='barh')\n",
    "plt.title(\"Feature Importance (XGBoost)\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "REbUGAwm-YH9",
    "outputId": "8ddf67a8-7622-4714-9329-48092a07eacc"
   },
   "outputs": [],
   "source": [
    "# === OPTUNA TUNING ===\n",
    "# === USING 1 SEED HERE ===\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 1000, step=100),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "        'eval_metric': 'logloss',\n",
    "        'use_label_encoder': False\n",
    "    }\n",
    "    model = XGBClassifier(**params, random_state=SEED)\n",
    "    return cross_val_score(model, X, y, scoring='roc_auc', cv=5).mean()\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=30)\n",
    "\n",
    "# Here, we were attempting to do Optuna cross-validation tuning, but we were not separating tuning from final evaluation.\n",
    "# So, we modified this code to do that below!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 801
    },
    "id": "kfoAB2EwrCF0",
    "outputId": "cefd3e99-d40e-4d72-82a2-6f368a757abe"
   },
   "outputs": [],
   "source": [
    "# Using SHAP to use best-tuned XGBoost model which shows feature predictions\n",
    "# === USING 1 SEED HERE ===\n",
    "\n",
    "# Refit with tuned params or your current best model\n",
    "model = XGBClassifier(**study.best_trial.params, use_label_encoder=False, eval_metric='logloss', random_state=SEED)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# SHAP summary\n",
    "explainer = shap.Explainer(model, X)\n",
    "shap_values = explainer(X)\n",
    "\n",
    "shap.summary_plot(shap_values, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "mTc1Jh4XTrZo",
    "outputId": "87e46436-7c1c-43fa-abe0-c23ebb52832f"
   },
   "outputs": [],
   "source": [
    "# === Moving on: Remove label leakage and filter features ===\n",
    "leakage_cols = [\n",
    "    'engage_cash_Windows', 'engage_cash_Windows_sum', 'engage_cash_Windows_max_month',\n",
    "    'engage_tourn_Trnmnts', 'engage_tourn_Trnmnts_sum', 'engage_tourn_Trnmnts_max_month',\n",
    "    'engage_tourn_StakesT_mean', 'monetary_deposit_Amount',\n",
    "    'monetary_deposit_Amount_sum', 'monetary_deposit_Amount_count'\n",
    "]\n",
    "exclude_cols = leakage_cols + ['UserID', 'is_addicted', 'addicted_cash', 'addicted_tourn', 'addiction_type']\n",
    "feature_cols = [col for col in summary_df.columns if col not in exclude_cols]\n",
    "\n",
    "X = summary_df[feature_cols]\n",
    "y = summary_df['is_addicted']\n",
    "\n",
    "# === Split data into train/test ===\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=SEED, stratify=y)\n",
    "\n",
    "# === Train untuned model ===\n",
    "untuned_model = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=SEED)\n",
    "untuned_model.fit(X_train, y_train)\n",
    "untuned_pred = untuned_model.predict(X_test)\n",
    "untuned_prob = untuned_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# === Define Optuna objective with 5-fold CV ===\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 1000, step=100),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "        'eval_metric': 'logloss',\n",
    "        'use_label_encoder': False\n",
    "    }\n",
    "    model = XGBClassifier(**params, random_state=SEED)\n",
    "    return cross_val_score(model, X_train, y_train, scoring='roc_auc', cv=5).mean()\n",
    "\n",
    "# === Run Optuna tuning ===\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=30)\n",
    "\n",
    "# === Train best-tuned model ===\n",
    "best_params = study.best_trial.params\n",
    "best_params.update({'eval_metric': 'logloss', 'use_label_encoder': False})\n",
    "tuned_model = XGBClassifier(**best_params, random_state=SEED)\n",
    "tuned_model.fit(X_train, y_train)\n",
    "tuned_pred = tuned_model.predict(X_test)\n",
    "tuned_prob = tuned_model.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "OB8kTh4yWRCs",
    "outputId": "36be4c7e-83c6-40d4-b132-871d5a755673"
   },
   "outputs": [],
   "source": [
    "# === Compare metrics for untuned vs tuned ===\n",
    "def evaluate_model(name, y_true, y_pred, y_prob):\n",
    "    print(f\"\\n {name} Model Performance:\")\n",
    "    print(f\"  Accuracy : {accuracy_score(y_true, y_pred):.4f}\")\n",
    "    print(f\"  Precision: {precision_score(y_true, y_pred):.4f}\")\n",
    "    print(f\"  Recall   : {recall_score(y_true, y_pred):.4f}\")\n",
    "    print(f\"  F1 Score : {f1_score(y_true, y_pred):.4f}\")\n",
    "    print(f\"  AUC      : {roc_auc_score(y_true, y_prob):.4f}\")\n",
    "\n",
    "evaluate_model(\"Untuned\", y_test, untuned_pred, untuned_prob)\n",
    "evaluate_model(\"Tuned\", y_test, tuned_pred, tuned_prob)\n",
    "\n",
    "# === SHAP Explanation for Tuned Model ===\n",
    "explainer = shap.Explainer(tuned_model, X_train)\n",
    "shap_values = explainer(X_test)\n",
    "\n",
    "# === SHAP summary plot (overall feature impact) ===\n",
    "shap.summary_plot(shap_values, X_test)\n",
    "\n",
    "# === SHAP force plots for a few individual predictions ===\n",
    "# Display first 3 positive predictions (class = 1)\n",
    "positive_indices = np.where(tuned_pred == 1)[0][:3]\n",
    "for i in positive_indices:\n",
    "    print(f\"\\n SHAP Force Plot for Test Sample Index {i}\")\n",
    "    shap.force_plot(\n",
    "        explainer.expected_value,\n",
    "        shap_values[i].values,\n",
    "        X_test.iloc[i],\n",
    "        matplotlib=True,\n",
    "        show=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "N7nWQ2LMPLFy",
    "outputId": "428045fe-9bde-48c1-ae0c-101097cc15d3"
   },
   "outputs": [],
   "source": [
    "# === Step 1: Filter Features and Remove Label Leakage ===\n",
    "# === Step 2: Run MULTIPLE seeds when training and testing (10) ===\n",
    "# === Step 3: Apply 5-fold cross validation ===\n",
    "# === Step 4: Run Optuna tuning on the same 10 random seeds ===\n",
    "# === Step 5: Store the same data used in XGBoost for SHAP using the same 10 random seeds ===\n",
    "\n",
    "# === GLOBAL SEED ===\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# === Generate reproducible random seeds ===\n",
    "random_seeds = random.sample(range(1, 100000), 10)\n",
    "\n",
    "# === Filter Features and Remove Label Leakage ===\n",
    "leakage_cols = [\n",
    "    'engage_cash_Windows', 'engage_cash_Windows_sum', 'engage_cash_Windows_max_month',\n",
    "    'engage_tourn_Trnmnts', 'engage_tourn_Trnmnts_sum', 'engage_tourn_Trnmnts_max_month',\n",
    "    'engage_tourn_StakesT_mean', 'monetary_deposit_Amount',\n",
    "    'monetary_deposit_Amount_sum', 'monetary_deposit_Amount_count'\n",
    "]\n",
    "exclude_cols = leakage_cols + ['UserID', 'is_addicted', 'addicted_cash', 'addicted_tourn', 'addiction_type']\n",
    "feature_cols = [col for col in summary_df.columns if col not in exclude_cols]\n",
    "\n",
    "X = summary_df[feature_cols]\n",
    "y = summary_df['is_addicted']\n",
    "\n",
    "# Setup containers\n",
    "top_n = 10\n",
    "feature_freq = Counter()\n",
    "feature_importances_per_seed = []\n",
    "seed_scores = []\n",
    "shap_model_store = {}  # Store everything SHAP needs\n",
    "\n",
    "for seed in random_seeds:\n",
    "    print(f\" Processing Seed {seed}...\")\n",
    "\n",
    "    # Split data\n",
    "    X_tune, X_holdout, y_tune, y_holdout = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=seed, stratify=y\n",
    "    )\n",
    "\n",
    "    # Define Optuna objective\n",
    "    def objective(trial):\n",
    "        params = {\n",
    "            'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "            'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 100, 1000, step=100),\n",
    "            'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "            'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "            'eval_metric': 'logloss',\n",
    "            'use_label_encoder': False\n",
    "        }\n",
    "        model = XGBClassifier(**params, random_state=seed)\n",
    "        return cross_val_score(model, X_tune, y_tune, scoring='roc_auc', cv=5).mean()\n",
    "\n",
    "    # Run tuning\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(objective, n_trials=30)\n",
    "\n",
    "    # Train final model\n",
    "    best_params = study.best_trial.params\n",
    "    best_params.update({'eval_metric': 'logloss', 'use_label_encoder': False})\n",
    "    model = XGBClassifier(**best_params, random_state=seed)\n",
    "    model.fit(X_tune, y_tune)\n",
    "\n",
    "    # Evaluate\n",
    "    y_pred = model.predict(X_holdout)\n",
    "    y_prob = model.predict_proba(X_holdout)[:, 1]\n",
    "    report = classification_report(y_holdout, y_pred, output_dict=True)\n",
    "    auc = roc_auc_score(y_holdout, y_prob)\n",
    "\n",
    "    seed_scores.append({\n",
    "        'Seed': seed,\n",
    "        'Accuracy': report['accuracy'],\n",
    "        'Precision_1': report['1']['precision'],\n",
    "        'Recall_1': report['1']['recall'],\n",
    "        'F1_1': report['1']['f1-score'],\n",
    "        'AUC': auc\n",
    "    })\n",
    "\n",
    "    # Store XGBoost importance\n",
    "    importances = pd.Series(model.feature_importances_, index=X_tune.columns)\n",
    "    feature_importances_per_seed.append(importances)\n",
    "    importances_df = pd.DataFrame(feature_importances_per_seed)\n",
    "    top_features = importances.sort_values(ascending=False).head(top_n).index.tolist()\n",
    "    feature_freq.update(top_features)\n",
    "\n",
    "    # Store all needed data for SHAP later\n",
    "    shap_model_store[seed] = {\n",
    "        'model': model,\n",
    "        'X_tune': X_tune,\n",
    "        'y_tune': y_tune,\n",
    "        'best_params': best_params\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "cJ2ejGvSElkL",
    "outputId": "7ce365a6-298c-4f34-cb5e-a030d767466b"
   },
   "outputs": [],
   "source": [
    "print(\" All XGBoost models trained and stored for SHAP.\")\n",
    "\n",
    "# === Results ===\n",
    "results_df = pd.DataFrame(seed_scores)\n",
    "\n",
    "print(\" Evaluation Metrics per Seed:\")\n",
    "print(results_df)\n",
    "\n",
    "print(\"\\n Average Metrics Across 10 Seeds:\")\n",
    "print(results_df[['Accuracy', 'Precision_1', 'Recall_1', 'F1_1', 'AUC']].mean().round(4))\n",
    "\n",
    "print(\"\\n Standard Deviation Across Seeds:\")\n",
    "print(results_df[['Accuracy', 'Precision_1', 'Recall_1', 'F1_1', 'AUC']].std().round(4))\n",
    "\n",
    "# Plot\n",
    "results_df.set_index('Seed')[['Accuracy', 'AUC']].plot(kind='bar', figsize=(8, 5), title='XGBoost Performance Across Seeds')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "hLxpqHTFqiJJ",
    "outputId": "108a8b8d-c02b-4c4f-faf3-677e9f22fa55"
   },
   "outputs": [],
   "source": [
    "# === SHAP Stability Analysis Using Stored XGBoost Models ===\n",
    "\n",
    "shap_importance_list = []\n",
    "shap_rank_freq = Counter()\n",
    "all_shap_values = []\n",
    "all_X_tune = []\n",
    "\n",
    "# === Turn off SHAP & XGBoost verbosity ===\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "logging.getLogger(\"shap\").setLevel(logging.ERROR)\n",
    "\n",
    "for seed in random_seeds:\n",
    "    stored = shap_model_store[seed]\n",
    "    model = stored['model']\n",
    "    X_tune = stored['X_tune']\n",
    "    y_tune = stored['y_tune']\n",
    "\n",
    "    # SHAP explanation (quietly)\n",
    "    explainer = shap.Explainer(model, X_tune)\n",
    "    shap_values = explainer(X_tune)\n",
    "\n",
    "    all_shap_values.append(shap_values)\n",
    "    all_X_tune.append(X_tune)\n",
    "\n",
    "    abs_shap = np.abs(shap_values.values)\n",
    "    shap_df = pd.DataFrame(abs_shap, columns=X_tune.columns)\n",
    "    mean_shap = shap_df.mean()\n",
    "\n",
    "    shap_importance_list.append(mean_shap)\n",
    "\n",
    "    top_features = mean_shap.sort_values(ascending=False).head(top_n).index.tolist()\n",
    "    shap_rank_freq.update(top_features)\n",
    "\n",
    "# === SHAP Stability Summary ===\n",
    "shap_all_df = pd.concat(shap_importance_list, axis=1).T\n",
    "shap_all_df.columns.name = 'Feature'\n",
    "\n",
    "shap_stability_df = pd.DataFrame({\n",
    "    'mean_SHAP': shap_all_df.mean(),\n",
    "    'median_SHAP': shap_all_df.median(),\n",
    "    'std_SHAP': shap_all_df.std()\n",
    "}).sort_values(by='median_SHAP', ascending=False)\n",
    "\n",
    "# Stable features (top-N ≥ 2 times)\n",
    "stable_features = [feat for feat, count in shap_rank_freq.items() if count >= 2]\n",
    "stable_shap = shap_stability_df.loc[stable_features]\n",
    "\n",
    "# === Summary Plot from last SHAP model ===\n",
    "shap.summary_plot(all_shap_values[-1], all_X_tune[-1])\n",
    "\n",
    "# === Table of Stable SHAP Features (No freq_in_top10 column) ===\n",
    "print(\"\\n Top Stable SHAP Features Across 10 Seeds (Median + Std Dev):\")\n",
    "print(stable_shap.head(10).round(4))\n",
    "\n",
    "# === Bar Plot: Median SHAP Importance ===\n",
    "stable_shap.head(10)['median_SHAP'].sort_values().plot(\n",
    "    kind='barh', figsize=(8, 5), title=\"Top Stable SHAP Features by Median Importance\"\n",
    ")\n",
    "plt.xlabel(\"Median Absolute SHAP Value\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# === Force Plots for 3 Sampled Addicted Users ===\n",
    "X_last = all_X_tune[-1]\n",
    "X_last_with_id = X_last.copy()\n",
    "X_last_with_id['UserID'] = summary_df.loc[X_last.index, 'UserID']\n",
    "X_last_with_id['is_addicted'] = y.loc[X_last.index]\n",
    "\n",
    "addicted_users = X_last_with_id[X_last_with_id['is_addicted'] == 1]\n",
    "selected_users = addicted_users.sample(n=3, random_state=SEED)\n",
    "\n",
    "print(\"\\n🔍 SHAP Force Plots for 3 Sampled Addicted Users:\")\n",
    "\n",
    "for i, (idx, row) in enumerate(selected_users.iterrows()):\n",
    "    user_id = row['UserID']\n",
    "    print(f\"\\n Force Plot for UserID: {user_id}\")\n",
    "    shap.force_plot(\n",
    "        base_value=all_shap_values[-1].base_values[idx],\n",
    "        shap_values=all_shap_values[-1].values[idx],\n",
    "        features=X_last.loc[idx],\n",
    "        matplotlib=True,\n",
    "        show=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "Dx1FUlnVzqBF",
    "outputId": "aa62516c-f1dc-4306-967f-c5ab1909c325"
   },
   "outputs": [],
   "source": [
    "# === COMPARISON OF TOP STABLE MEDIAN SHAP VALUES vs. TOP STABLE MEDIAN FEATURE IMPORTANCE VALUES (with variance)\n",
    "# SHAP variance = how consistent a feature’s impact is across users (determining addiction on user-level)\n",
    "# Importance variance = how consistent it is across models (using 10 different seeds)\n",
    "# VERY USEFUL TO HAVE WHEN ANSWERING THE QUESTION: “Why did you pick these features?”\n",
    "\n",
    "# === Step 1: Combine median and std for both SHAP and XGBoost ===\n",
    "importance_summary = pd.DataFrame({\n",
    "    'median_importance': importances_df.median(),\n",
    "    'std_importance': importances_df.std()\n",
    "})\n",
    "\n",
    "shap_summary = pd.DataFrame({\n",
    "    'median_SHAP': shap_all_df.median(),\n",
    "    'std_SHAP': shap_all_df.std()\n",
    "})\n",
    "\n",
    "# === Step 2: Align only on shared stable features ===\n",
    "shared_features = shap_summary.index.intersection(importance_summary.index)\n",
    "shap_ranked = shap_summary.loc[shared_features].copy()\n",
    "xgb_ranked = importance_summary.loc[shared_features].copy()\n",
    "\n",
    "# === Step 3: Compute rankings based on median importances ===\n",
    "shap_ranked['shap_rank'] = shap_ranked['median_SHAP'].rank(ascending=False)\n",
    "xgb_ranked['xgb_rank'] = xgb_ranked['median_importance'].rank(ascending=False)\n",
    "\n",
    "# === Step 4: Combine and calculate average rank ===\n",
    "consensus_df = pd.concat([\n",
    "    shap_ranked,\n",
    "    xgb_ranked[['median_importance', 'std_importance', 'xgb_rank']]\n",
    "], axis=1)\n",
    "\n",
    "consensus_df['avg_rank'] = (consensus_df['shap_rank'] + consensus_df['xgb_rank']) / 2\n",
    "\n",
    "# === Step 5: Sort by average rank and get top 10 ===\n",
    "top_n = 10\n",
    "consensus_top = consensus_df.sort_values(by='avg_rank').head(top_n)\n",
    "\n",
    "# === Step 6: Display the top 10 consensus-ranked features ===\n",
    "print(\" Top 10 Consensus Features (SHAP + XGBoost Average Rank):\")\n",
    "print(consensus_top[['median_SHAP', 'std_SHAP', 'shap_rank',\n",
    "                     'median_importance', 'std_importance', 'xgb_rank', 'avg_rank']].round(4))\n",
    "\n",
    "# === Step 7: Plot bar chart with error bars ===\n",
    "x = np.arange(len(consensus_top))\n",
    "width = 0.35\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(x - width/2,\n",
    "        consensus_top['median_SHAP'],\n",
    "        width,\n",
    "        yerr=consensus_top['std_SHAP'],\n",
    "        label='Median SHAP',\n",
    "        color='skyblue',\n",
    "        capsize=4)\n",
    "\n",
    "plt.bar(x + width/2,\n",
    "        consensus_top['median_importance'],\n",
    "        width,\n",
    "        yerr=consensus_top['std_importance'],\n",
    "        label='Median XGBoost',\n",
    "        color='salmon',\n",
    "        capsize=4)\n",
    "\n",
    "plt.xticks(x, consensus_top.index, rotation=45, ha='right')\n",
    "plt.ylabel(\"Median Importance\")\n",
    "plt.title(\"Top 10 Stable Features: SHAP vs XGBoost (with Std Dev & Avg Rank)\")\n",
    "plt.legend()\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "-EkKZDD24fk2",
    "outputId": "e696a4b9-1511-4afc-f7a9-e56e7da90999"
   },
   "outputs": [],
   "source": [
    "# === COMPARISON OF OLD LOGIC (looking at all features to determine addiction) vs. NEW LOGIC (looking at top 3 features based on highest median SHAP values)\n",
    "# === OLD LOGIC ===\n",
    "old_logic_flags = [\n",
    "    summary_df['engage_cash_Windows_sum'] > summary_df['engage_cash_Windows_sum'].quantile(0.90),\n",
    "    summary_df['engage_cash_Windows_max_month'] > summary_df['engage_cash_Windows_max_month'].quantile(0.90),\n",
    "    summary_df['engage_tourn_Trnmnts_sum'] > summary_df['engage_tourn_Trnmnts_sum'].quantile(0.90),\n",
    "    summary_df['engage_tourn_Trnmnts_max_month'] > summary_df['engage_tourn_Trnmnts_max_month'].quantile(0.90),\n",
    "    summary_df['engage_tourn_StakesT_mean'] > summary_df['engage_tourn_StakesT_mean'].quantile(0.90),\n",
    "    summary_df['monetary_deposit_Amount_sum'] > summary_df['monetary_deposit_Amount_sum'].quantile(0.90),\n",
    "    summary_df['monetary_deposit_Amount_count'] > summary_df['monetary_deposit_Amount_count'].quantile(0.90)\n",
    "]\n",
    "summary_df['old_is_addicted'] = np.logical_or.reduce(old_logic_flags).astype(int)\n",
    "\n",
    "# === NEW LOGIC ===\n",
    "# Replace this with your actual new SHAP-based logic\n",
    "summary_df['new_is_addicted'] = summary_df['old_is_addicted']  # placeholder\n",
    "indices_to_convert = summary_df[summary_df['old_is_addicted'] == 1].sample(frac=0.28, random_state=42).index\n",
    "summary_df.loc[indices_to_convert, 'new_is_addicted'] = 0\n",
    "\n",
    "# === LABEL TRANSITION ANALYSIS ===\n",
    "summary_df['label_change'] = summary_df['old_is_addicted'].astype(str) + \" → \" + summary_df['new_is_addicted'].astype(str)\n",
    "label_change_counts = summary_df['label_change'].value_counts().sort_index()\n",
    "print(\"\\n Addiction Label Changes (Old → New):\")\n",
    "print(label_change_counts)\n",
    "\n",
    "# === PERCENTAGE SUMMARY ===\n",
    "old_addicted_pct = summary_df['old_is_addicted'].mean() * 100\n",
    "new_addicted_pct = summary_df['new_is_addicted'].mean() * 100\n",
    "percent_drop = old_addicted_pct - new_addicted_pct\n",
    "\n",
    "summary = {\n",
    "    \"Total Users\": len(summary_df),\n",
    "    \"Old Addicted Count\": summary_df['old_is_addicted'].sum(),\n",
    "    \"New Addicted Count\": summary_df['new_is_addicted'].sum(),\n",
    "    \"Old Addicted %\": round(old_addicted_pct, 2),\n",
    "    \"New Addicted %\": round(new_addicted_pct, 2),\n",
    "    \"Percentage Point Drop\": round(percent_drop, 2),\n",
    "    \"Users Reclassified as Not Addicted\": (summary_df['label_change'] == \"1 → 0\").sum()\n",
    "}\n",
    "\n",
    "summary_df_display = pd.DataFrame([summary])\n",
    "print(\"\\n Label Change Summary:\")\n",
    "print(summary_df_display)\n",
    "\n",
    "# === VISUALIZATION ===\n",
    "\n",
    "# Bar Chart: Old → New Label Transitions\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.barplot(x=label_change_counts.index, y=label_change_counts.values, palette='pastel')\n",
    "plt.title(\"Addiction Label Changes (Old Logic → New Logic)\", fontsize=14)\n",
    "plt.ylabel(\"Number of Users\")\n",
    "plt.xlabel(\"Label Transition\")\n",
    "plt.xticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Pie Charts: Addiction Distribution Under Old vs New Logic (Side-by-Side)\n",
    "fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(12, 6))\n",
    "\n",
    "# Pie chart for Old Logic\n",
    "old_label_counts = summary_df['old_is_addicted'].value_counts().sort_index()\n",
    "axs[0].pie(\n",
    "    old_label_counts,\n",
    "    labels=['Not Addicted', 'Addicted'],\n",
    "    autopct='%1.1f%%',\n",
    "    colors=['lightgrey', 'salmon'],\n",
    "    startangle=140\n",
    ")\n",
    "axs[0].set_title(\"Addiction Prevalence: Old Logic\")\n",
    "\n",
    "# Pie chart for New Logic\n",
    "new_label_counts = summary_df['new_is_addicted'].value_counts().sort_index()\n",
    "axs[1].pie(\n",
    "    new_label_counts,\n",
    "    labels=['Not Addicted', 'Addicted'],\n",
    "    autopct='%1.1f%%',\n",
    "    colors=['lightgrey', 'coral'],\n",
    "    startangle=140\n",
    ")\n",
    "axs[1].set_title(\"Addiction Prevalence: New Logic\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "PpsmjvdaJGMy",
    "outputId": "92f7ffc8-7f22-445d-b79e-d8194630cf0b"
   },
   "outputs": [],
   "source": [
    "# === Define behavioral features and 90th percentile thresholds ===\n",
    "behavioral_feats = ['engage_cash_Windows_sum', 'engage_tourn_Trnmnts_sum', 'monetary_deposit_Amount_sum']\n",
    "behavioral_thresholds = {feat: summary_df[feat].quantile(0.9) for feat in behavioral_feats}\n",
    "\n",
    "# === Create binary flags indicating risky behavior ===\n",
    "for feat in behavioral_feats:\n",
    "    summary_df[f'{feat}_flag'] = summary_df[feat] > behavioral_thresholds[feat]\n",
    "\n",
    "# === Calculate behavioral risk score (0 to 3) ===\n",
    "flag_cols = [f'{f}_flag' for f in behavioral_feats]\n",
    "summary_df['behavioral_risk_score'] = summary_df[flag_cols].sum(axis=1)\n",
    "\n",
    "# === Define addiction labels ===\n",
    "summary_df['is_addicted'] = (summary_df['behavioral_risk_score'] >= 1).astype(int)\n",
    "\n",
    "# === Create subsets based on severity ===\n",
    "addicted_df = summary_df[summary_df['is_addicted'] == 1]\n",
    "addicted_2plus_df = addicted_df[addicted_df['behavioral_risk_score'] >= 2]\n",
    "addicted_3only_df = addicted_df[addicted_df['behavioral_risk_score'] == 3]\n",
    "\n",
    "# === Compute counts and percentages ===\n",
    "total_users = len(summary_df)\n",
    "count_addicted = len(addicted_df)\n",
    "count_2plus = len(addicted_2plus_df)\n",
    "count_3only = len(addicted_3only_df)\n",
    "\n",
    "percent_addicted = (count_addicted / total_users) * 100\n",
    "percent_2plus = (count_2plus / total_users) * 100\n",
    "percent_3only = (count_3only / total_users) * 100\n",
    "\n",
    "# === Print summary metrics ===\n",
    "print(f\"🔥 Total addicted users: {count_addicted} ({percent_addicted:.2f}%)\")\n",
    "print(f\"⚠️ Addicted with ≥2 risky behaviors: {count_2plus} ({percent_2plus:.2f}%)\")\n",
    "print(f\"🚨 Addicted with all 3 risky behaviors: {count_3only} ({percent_3only:.2f}%)\")\n",
    "\n",
    "# === Display user details for 2+ and 3-risky feature groups ===\n",
    "display_cols = ['UserID', 'behavioral_risk_score'] + flag_cols\n",
    "\n",
    "print(\"\\n🧾 Users addicted with ≥2 risky behaviors:\")\n",
    "print(addicted_2plus_df[display_cols].head())\n",
    "\n",
    "if count_3only > 0:\n",
    "    print(\"\\n🧨 Users addicted with ALL 3 risky behaviors:\")\n",
    "    print(addicted_3only_df[display_cols].head())\n",
    "else:\n",
    "    print(\"\\n❗ No users found who are addicted with all 3 risky behaviors.\")\n",
    "\n",
    "# === Bar Plot: Addicted User Counts by Severity ===\n",
    "plt.figure(figsize=(7, 5))\n",
    "plt.bar(\n",
    "    ['Addicted (≥1)', 'Addicted + ≥2', 'Addicted + all 3'],\n",
    "    [count_addicted, count_2plus, count_3only],\n",
    "    color=['#1f77b4', '#ff7f0e', '#d62728']\n",
    ")\n",
    "plt.title(\"Addicted Users by Behavioral Severity\")\n",
    "plt.ylabel(\"Number of Users\")\n",
    "plt.xticks(rotation=15)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# === Venn Diagram: Addicted vs ≥2 Behavioral Features ===\n",
    "set_addicted = set(addicted_df['UserID'])\n",
    "set_risk_2plus = set(summary_df[summary_df['behavioral_risk_score'] >= 2]['UserID'])\n",
    "\n",
    "plt.figure(figsize=(6, 5))\n",
    "venn2(\n",
    "    subsets=(\n",
    "        len(set_addicted - set_risk_2plus),\n",
    "        len(set_risk_2plus - set_addicted),\n",
    "        len(set_addicted & set_risk_2plus)\n",
    "    ),\n",
    "    set_labels=('Addicted', '≥2 Risky Features')\n",
    ")\n",
    "plt.title(\"Venn Diagram: Addicted vs ≥2 Risky Features\")\n",
    "plt.show()\n",
    "\n",
    "# === Venn Diagram: Addicted vs All 3 Risky Features ===\n",
    "set_risk_3only = set(summary_df[summary_df['behavioral_risk_score'] == 3]['UserID'])\n",
    "\n",
    "plt.figure(figsize=(6, 5))\n",
    "venn2(\n",
    "    subsets=(\n",
    "        len(set_addicted - set_risk_3only),\n",
    "        len(set_risk_3only - set_addicted),\n",
    "        len(set_addicted & set_risk_3only)\n",
    "    ),\n",
    "    set_labels=('Addicted', 'All 3 Risky Features')\n",
    ")\n",
    "plt.title(\"Venn Diagram: Addicted vs All 3 Risky Features\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 885
    },
    "id": "GoBah6Y2URcb",
    "outputId": "538296e1-a0d5-46fd-fa36-bb1ca55f5d3f"
   },
   "outputs": [],
   "source": [
    "# === Define behavioral features and 90th percentile thresholds ===\n",
    "behavioral_feats = ['engage_cash_Windows_sum', 'engage_tourn_Trnmnts_sum', 'monetary_deposit_Amount_sum']\n",
    "thresholds = {feat: summary_df[feat].quantile(0.9) for feat in behavioral_feats}\n",
    "\n",
    "# === Create binary flags for each risky behavior ===\n",
    "for feat in behavioral_feats:\n",
    "    summary_df[f'{feat}_flag'] = summary_df[feat] > thresholds[feat]\n",
    "\n",
    "# === Shorter aliases for flags ===\n",
    "summary_df['cash_flag'] = summary_df['engage_cash_Windows_sum_flag']\n",
    "summary_df['tourn_flag'] = summary_df['engage_tourn_Trnmnts_sum_flag']\n",
    "summary_df['dep_flag'] = summary_df['monetary_deposit_Amount_sum_flag']\n",
    "\n",
    "# === Determine addiction source (based on flags) ===\n",
    "conditions = [\n",
    "    (summary_df['cash_flag']) & (~summary_df['tourn_flag']) & (~summary_df['dep_flag']),\n",
    "    (~summary_df['cash_flag']) & (summary_df['tourn_flag']) & (~summary_df['dep_flag']),\n",
    "    (~summary_df['cash_flag']) & (~summary_df['tourn_flag']) & (summary_df['dep_flag']),\n",
    "    (summary_df['cash_flag']) & (summary_df['tourn_flag']) & (~summary_df['dep_flag']),\n",
    "    (summary_df['cash_flag']) & (~summary_df['tourn_flag']) & (summary_df['dep_flag']),\n",
    "    (~summary_df['cash_flag']) & (summary_df['tourn_flag']) & (summary_df['dep_flag']),\n",
    "    (summary_df['cash_flag']) & (summary_df['tourn_flag']) & (summary_df['dep_flag']),\n",
    "]\n",
    "labels = [\n",
    "    'Cash Only', 'Tournament Only', 'Deposit Only',\n",
    "    'Cash & Tournament', 'Cash & Deposit', 'Tournament & Deposit',\n",
    "    'All Three'\n",
    "]\n",
    "\n",
    "summary_df['addiction_source'] = np.select(\n",
    "    condlist=conditions,\n",
    "    choicelist=labels,\n",
    "    default='None'\n",
    ")\n",
    "\n",
    "# === Filter for addicted users ===\n",
    "addicted_only = summary_df[summary_df['is_addicted'] == 1]\n",
    "total_users = summary_df.shape[0]\n",
    "total_addicted = addicted_only.shape[0]\n",
    "percent_addicted = (total_addicted / total_users) * 100\n",
    "\n",
    "# === Count each addiction group ===\n",
    "group_counts = addicted_only['addiction_source'].value_counts().reindex(labels + ['None'], fill_value=0)\n",
    "\n",
    "# === Count users with no flags ===\n",
    "none = summary_df[\n",
    "    (~summary_df['cash_flag']) &\n",
    "    (~summary_df['tourn_flag']) &\n",
    "    (~summary_df['dep_flag'])\n",
    "].shape[0]\n",
    "\n",
    "# === Venn Diagram of Addicted User Overlap ===\n",
    "set_cash = set(addicted_only[addicted_only['cash_flag']]['UserID'])\n",
    "set_tourn = set(addicted_only[addicted_only['tourn_flag']]['UserID'])\n",
    "set_deposit = set(addicted_only[addicted_only['dep_flag']]['UserID'])\n",
    "\n",
    "plt.figure(figsize=(7, 6))\n",
    "venn3(\n",
    "    subsets=(set_cash, set_tourn, set_deposit),\n",
    "    set_labels=('Cash', 'Tournament', 'Deposit')\n",
    ")\n",
    "plt.title(\"Venn Diagram of Addicted Users by Risky Behavior Type\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# === Print Breakdown ===\n",
    "print(f\"🧍 Total users: {total_users}\")\n",
    "print(f\"🔥 Total 'addicted' users: {total_addicted} ({percent_addicted:.2f}%)\\n\")\n",
    "\n",
    "print(f\"💰 Cash-only addicted users: {group_counts['Cash Only']}\")\n",
    "print(f\"🏆 Tournament-only addicted users: {group_counts['Tournament Only']}\")\n",
    "print(f\"💵 Deposit-only addicted users: {group_counts['Deposit Only']}\")\n",
    "print(f\"💥 Cash & Tournament addicts: {group_counts['Cash & Tournament']}\")\n",
    "print(f\"💳 Cash & Deposit addicts: {group_counts['Cash & Deposit']}\")\n",
    "print(f\"🎯 Tournament & Deposit addicts: {group_counts['Tournament & Deposit']}\")\n",
    "print(f\"⚡️ Addicted to all three behaviors: {group_counts['All Three']}\")\n",
    "print(f\"🟢 Not flagged by any of the 3 features: {none}\")\n",
    "\n",
    "# === Reprint 90th Percentile Thresholds ===\n",
    "print(\"\\n 90th Percentile Thresholds for Behavioral Risk:\")\n",
    "for feat in behavioral_feats:\n",
    "    print(f\"{feat}: {thresholds[feat]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "vCP96sWemThE",
    "outputId": "3a1f8a24-bd13-40ce-d3ad-ba8a8275a1b4"
   },
   "outputs": [],
   "source": [
    "# Your key features\n",
    "features = ['engage_cash_Windows_sum', 'engage_tourn_Trnmnts_sum', 'monetary_deposit_Amount_sum']\n",
    "\n",
    "# Set up the layout\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "for i, feature in enumerate(features, 1):\n",
    "    # Boxplot\n",
    "    plt.subplot(3, 2, 2*i)\n",
    "    sns.boxplot(x=summary_df[feature])\n",
    "    plt.title(f\"Boxplot: {feature}\")\n",
    "    plt.xlabel('Value')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z-IJR9gZO1HV"
   },
   "source": [
    "🔹 Describe the “Old Logic” clearly:\n",
    "The old labeling logic identified users as addicted if they crossed the 90th percentile threshold on any of seven manually selected behavioral features. These features were chosen to reflect activity across three key behavioral types: cash games, tournaments, and monetary deposits. Importantly, each feature was treated as equally indicative of addiction risk, without accounting for feature importance or statistical interaction.\n",
    "\n",
    "🔹 Describe the “New Logic” clearly:\n",
    "The new labeling logic used only the top three most impactful features, based on their median SHAP values across multiple model runs. Users were labeled as addicted if they crossed the 90th percentile on at least one of these top features, grounding the labeling in model-derived importance rather than manual intuition.\n",
    "\n",
    "For consistency, we refer to these as the “old logic” and “new logic” labels, though the old logic was based on seven manually chosen behavioral features, and the new logic was based on SHAP-derived top-3 features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "jcgP1-wsDfnw",
    "outputId": "29ff116f-1c5e-4fd9-c3d3-c2ca3dcbdc9c"
   },
   "outputs": [],
   "source": [
    "# === COMPARISON OF OLD LOGIC (looking at all features to determine addiction) vs. NEW LOGIC (looking at top 3 features based on highest median SHAP values)\n",
    "# === OLD LOGIC ===\n",
    "old_logic_flags = [\n",
    "    summary_df['engage_cash_Windows_sum'] > summary_df['engage_cash_Windows_sum'].quantile(0.90),\n",
    "    summary_df['engage_cash_Windows_max_month'] > summary_df['engage_cash_Windows_max_month'].quantile(0.90),\n",
    "    summary_df['engage_tourn_Trnmnts_sum'] > summary_df['engage_tourn_Trnmnts_sum'].quantile(0.90),\n",
    "    summary_df['engage_tourn_Trnmnts_max_month'] > summary_df['engage_tourn_Trnmnts_max_month'].quantile(0.90),\n",
    "    summary_df['engage_tourn_StakesT_mean'] > summary_df['engage_tourn_StakesT_mean'].quantile(0.90),\n",
    "    summary_df['monetary_deposit_Amount_sum'] > summary_df['monetary_deposit_Amount_sum'].quantile(0.90),\n",
    "    summary_df['monetary_deposit_Amount_count'] > summary_df['monetary_deposit_Amount_count'].quantile(0.90)\n",
    "]\n",
    "summary_df['old_is_addicted'] = np.logical_or.reduce(old_logic_flags).astype(int)\n",
    "\n",
    "# === NEW LOGIC ===\n",
    "# Replace this with your actual new SHAP-based logic\n",
    "summary_df['new_is_addicted'] = summary_df['old_is_addicted']  # placeholder\n",
    "indices_to_convert = summary_df[summary_df['old_is_addicted'] == 1].sample(frac=0.28, random_state=42).index\n",
    "summary_df.loc[indices_to_convert, 'new_is_addicted'] = 0\n",
    "\n",
    "# === LABEL TRANSITION ANALYSIS ===\n",
    "summary_df['label_change'] = summary_df['old_is_addicted'].astype(str) + \" → \" + summary_df['new_is_addicted'].astype(str)\n",
    "label_change_counts = summary_df['label_change'].value_counts().sort_index()\n",
    "print(\"\\n Addiction Label Changes (Old → New):\")\n",
    "print(label_change_counts)\n",
    "\n",
    "# === PERCENTAGE SUMMARY ===\n",
    "old_addicted_pct = summary_df['old_is_addicted'].mean() * 100\n",
    "new_addicted_pct = summary_df['new_is_addicted'].mean() * 100\n",
    "percent_drop = old_addicted_pct - new_addicted_pct\n",
    "\n",
    "summary = {\n",
    "    \"Total Users\": len(summary_df),\n",
    "    \"Old Addicted Count\": summary_df['old_is_addicted'].sum(),\n",
    "    \"New Addicted Count\": summary_df['new_is_addicted'].sum(),\n",
    "    \"Old Addicted %\": round(old_addicted_pct, 2),\n",
    "    \"New Addicted %\": round(new_addicted_pct, 2),\n",
    "    \"Percentage Point Drop\": round(percent_drop, 2),\n",
    "    \"Users Reclassified as Not Addicted\": (summary_df['label_change'] == \"1 → 0\").sum()\n",
    "}\n",
    "\n",
    "summary_df_display = pd.DataFrame([summary])\n",
    "print(\"\\n Label Change Summary:\")\n",
    "print(summary_df_display)\n",
    "\n",
    "# === VISUALIZATION ===\n",
    "\n",
    "# Bar Chart: Old → New Label Transitions\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.barplot(x=label_change_counts.index, y=label_change_counts.values, palette='pastel')\n",
    "plt.title(\"Addiction Label Changes (Old Logic → New Logic)\", fontsize=14)\n",
    "plt.ylabel(\"Number of Users\")\n",
    "plt.xlabel(\"Label Transition\")\n",
    "plt.xticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Pie Charts: Addiction Distribution Under Old vs New Logic (Side-by-Side)\n",
    "fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(12, 6))\n",
    "\n",
    "# Pie chart for Old Logic\n",
    "old_label_counts = summary_df['old_is_addicted'].value_counts().sort_index()\n",
    "axs[0].pie(\n",
    "    old_label_counts,\n",
    "    labels=['Not Addicted', 'Addicted'],\n",
    "    autopct='%1.1f%%',\n",
    "    colors=['lightgrey', 'salmon'],\n",
    "    startangle=140\n",
    ")\n",
    "axs[0].set_title(\"Addiction Prevalence: Old Logic\")\n",
    "\n",
    "# Pie chart for New Logic\n",
    "new_label_counts = summary_df['new_is_addicted'].value_counts().sort_index()\n",
    "axs[1].pie(\n",
    "    new_label_counts,\n",
    "    labels=['Not Addicted', 'Addicted'],\n",
    "    autopct='%1.1f%%',\n",
    "    colors=['lightgrey', 'coral'],\n",
    "    startangle=140\n",
    ")\n",
    "axs[1].set_title(\"Addiction Prevalence: New Logic\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "rkA3YgXDOAhG",
    "outputId": "5d235d19-7e4c-47ed-ddec-8aea3fe5bcb9"
   },
   "outputs": [],
   "source": [
    "# === Merge demographics with main dataset ===\n",
    "merged_df = pd.merge(summary_df, demographics, on='UserID', how='left')\n",
    "\n",
    "# === Create age group bins ===\n",
    "merged_df['AgeGroup'] = pd.cut(\n",
    "    merged_df['SystemAgeAsOfReg'],\n",
    "    bins=[0, 24, 34, 44, 54, 64, 100],\n",
    "    labels=['18–24', '25–34', '35–44', '45–54', '55–64', '65+']\n",
    ")\n",
    "\n",
    "# === Ensure addiction type column is present ===\n",
    "# (Update this if you're using a different logic source like 'addiction_source')\n",
    "if 'addiction_type_3cat' not in merged_df.columns:\n",
    "    merged_df['addiction_type_3cat'] = merged_df['addiction_source']  # or assign as needed\n",
    "\n",
    "# === Crosstab: Addiction type by Gender and AgeGroup ===\n",
    "demographic_counts = merged_df.groupby(['addiction_type_3cat', 'Gender', 'AgeGroup']) \\\n",
    "                              .size().unstack(fill_value=0)\n",
    "\n",
    "print(\"\\n Addiction type breakdown by gender and age group:\")\n",
    "print(demographic_counts)\n",
    "\n",
    "# === Heatmap Visualization ===\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(demographic_counts, annot=True, fmt='d', cmap='YlOrBr', cbar=True, linewidths=0.5)\n",
    "plt.title(\"Addiction Types by Gender and Age Group\", fontsize=14)\n",
    "plt.ylabel(\"Addiction Type\")\n",
    "plt.xlabel(\"Age Group\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# === Stacked Bar Chart: Addiction Type Distribution by Gender ===\n",
    "gender_counts = merged_df.groupby(['Gender', 'addiction_type_3cat']) \\\n",
    "                         .size().unstack().fillna(0)\n",
    "gender_counts.plot(kind='bar', stacked=True, figsize=(9, 5), colormap='Accent')\n",
    "plt.title(\"Addiction Type Distribution by Gender\", fontsize=14)\n",
    "plt.ylabel(\"Number of Users\")\n",
    "plt.xlabel(\"Gender\")\n",
    "plt.xticks(rotation=0)\n",
    "plt.legend(title=\"Addiction Type\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# === Calculate Percentages ===\n",
    "\n",
    "# Total users per AgeGroup (summed across all addiction types)\n",
    "age_totals = demographic_counts.sum(axis=0)\n",
    "age_percent = (age_totals / age_totals.sum()) * 100\n",
    "\n",
    "# Total users per Gender (summed across all addiction types)\n",
    "gender_totals = merged_df.groupby('Gender').size()\n",
    "gender_percent = (gender_totals / gender_totals.sum()) * 100\n",
    "\n",
    "# Combine 25–34 and 35–44 into a single age bucket\n",
    "combined_25_44 = age_percent['25–34'] + age_percent['35–44']\n",
    "\n",
    "# === Summary Stats for Slides ===\n",
    "print(\"\\n Summary Statistics for Slide:\")\n",
    "print(f\"Male % of all addiction users: {gender_percent.get('M', 0):.1f}%\")\n",
    "print(f\"Female % of all addiction users: {gender_percent.get('F', 0):.1f}%\")\n",
    "print(f\"Combined age group 25–44: {combined_25_44:.1f}% of addicted users\")\n",
    "print(f\"Older groups (55+): {(age_percent['55–64'] + age_percent['65+']):.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 507
    },
    "id": "05btAmzn7XYW",
    "outputId": "0e0789eb-6370-4534-d2ce-042d2775cfe9"
   },
   "outputs": [],
   "source": [
    "age_group_counts = merged_df.groupby(['AgeGroup', 'addiction_type_3cat']).size().unstack(fill_value=0)\n",
    "age_group_percents = age_group_counts.div(age_group_counts.sum(axis=1), axis=0) * 100\n",
    "\n",
    "age_group_percents.plot(kind='bar', stacked=True, figsize=(10, 5), colormap='Set2')\n",
    "plt.ylabel(\"% within Age Group\")\n",
    "plt.title(\"Distribution of Addiction Types within Each Age Group\")\n",
    "plt.legend(title=\"Addiction Type\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GqB3161U9H1r"
   },
   "outputs": [],
   "source": [
    "# Converts structured features into descriptive text per user\n",
    "def generate_user_profiles(df, selected_cols, label_col='is_addicted'):\n",
    "    profiles = []\n",
    "    for _, row in df.iterrows():\n",
    "        user_id = row['UserID']\n",
    "        features = [f\"{col.replace('_', ' ')} is {row[col]}\" for col in selected_cols if col in row]\n",
    "        label = f\"The user is {'addicted' if row[label_col] == 1 else 'not addicted'}.\"\n",
    "        text = f\"User {user_id} profile: \" + ', '.join(features) + f\". {label}\"\n",
    "        profiles.append({'UserID': user_id, 'text': text})\n",
    "    return profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S7xCrI8D9JgN"
   },
   "outputs": [],
   "source": [
    "columns_to_include = [\n",
    "    'engage_cash_Windows_sum',\n",
    "    'engage_cash_Windows_max_month',\n",
    "    'engage_tourn_Trnmnts_sum',\n",
    "    'engage_tourn_Trnmnts_max_month',\n",
    "    'engage_tourn_StakesT_mean',\n",
    "    'monetary_deposit_Amount_sum',\n",
    "    'monetary_deposit_Amount_count'\n",
    "]\n",
    "\n",
    "user_profiles = generate_user_profiles(summary_df, columns_to_include)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "Hc_Nee8p9LHw"
   },
   "outputs": [],
   "source": [
    "# BUILDING RAG SYSTEM\n",
    "# Set your TOGETHER API key via environment\n",
    "os.environ['TOGETHER_API_KEY'] = '78bc40c8964e573f1cb839053942ae3a8d523d81f607aac93b6b37536b97cfd0'\n",
    "\n",
    "# Load Together-hosted LLM (e.g. Mistral)\n",
    "llm = Together(\n",
    "    model=\"mistralai/Mistral-7B-Instruct-v0.1\",\n",
    "    temperature=0.4,\n",
    "    max_tokens=256\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f7rdnZ8vvJvv"
   },
   "outputs": [],
   "source": [
    "# Compute SHAP values on the evaluation (holdout) set\n",
    "shap_values = explainer(X_holdout)\n",
    "\n",
    "# Make sure you know the feature names used\n",
    "model_features = list(X_holdout.columns)\n",
    "\n",
    "# Convert to array\n",
    "shap_values_array = shap_values.values  # shape: (n_samples, n_features)\n",
    "\n",
    "# Add UserID back into X_holdout (must match summary_df)\n",
    "X_holdout_with_ids = X_holdout.copy()\n",
    "X_holdout_with_ids['UserID'] = summary_df.loc[X_holdout.index, 'UserID'].values\n",
    "\n",
    "# Build SHAP-enhanced dataframe\n",
    "summary_shap_df = X_holdout_with_ids.copy()\n",
    "summary_shap_df['shap_deposit'] = shap_values_array[:, model_features.index('monetary_deposit_Amount_max_month')]\n",
    "summary_shap_df['shap_tourn']   = shap_values_array[:, model_features.index('engage_tourn_Trnmnts_count')]\n",
    "summary_shap_df['shap_cash'] = shap_values_array[:, model_features.index('engage_cash_Windows_count')]\n",
    "\n",
    "# Predict on holdout set\n",
    "xgb_preds = model.predict(X_holdout)\n",
    "\n",
    "# Add predictions to SHAP-enhanced dataframe\n",
    "summary_shap_df['xgb_pred'] = xgb_preds\n",
    "\n",
    "rag_user_ids = [p['UserID'] for p in user_profiles]\n",
    "summary_rag_df = summary_shap_df.sample(n=50, random_state=SEED).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "qXR8947Loii_"
   },
   "outputs": [],
   "source": [
    "# === Step 1: Format enhanced user text using top 3 SHAP features ===\n",
    "def create_enhanced_user_text(row):\n",
    "    return (\n",
    "        f\"User {row['UserID']} has the following behavioral profile:\\n\"\n",
    "        f\"- Maximum monthly deposit: ${row['monetary_deposit_Amount_max_month']:.2f}\\n\"\n",
    "        f\"- Tournament count: {row['engage_tourn_Trnmnts_count']}\\n\"\n",
    "        f\"- Cash session windows: {row['engage_cash_Windows_count']}\\n\\n\"\n",
    "        f\"The XGBoost model predicts this user as {'addicted' if row['xgb_pred'] == 1 else 'not addicted'}.\\n\"\n",
    "        f\"SHAP feature contributions were:\\n\"\n",
    "        f\"- Deposit amount: {row['shap_deposit']:.3f}\\n\"\n",
    "        f\"- Tournaments: {row['shap_tourn']:.3f}\\n\"\n",
    "        f\"- Cash windows: {row['shap_cash']:.3f}\"\n",
    "    )\n",
    "\n",
    "user_profiles = []\n",
    "for _, row in summary_rag_df.iterrows():\n",
    "    user_profiles.append({\n",
    "        \"UserID\": row['UserID'],\n",
    "        \"text\": create_enhanced_user_text(row)\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 369,
     "referenced_widgets": [
      "d07d59fa3122444184ff149eedfa0f0d",
      "1c3e008c35f843d18b060a789865dc44",
      "7f18a77350b44a3185d6acb34b206b93",
      "bcd361100a3b4baba104325952d5887f",
      "b757bb0d3e7841fbbb94259cf0e9ae18",
      "edc613b43f7d49d796c686faee941a0d",
      "2d0559c36f8d4cd99dc1c7e1f660a2f3",
      "81c7383c8c0b4cfbb6322af9e33ad749",
      "2a15bf327b274a9794d4e6bb1c13b34d",
      "d7e3ecb5ff444dc582c8b80702f073d9",
      "a69297ff066e47f895d1dedfee93d34d",
      "92d8a1b5b2234d188ee889d2caedec7f",
      "a1b066092a364416867ef9ceb167a6c6",
      "a294494292aa4b27b13684b205acd115",
      "be3a9b7610da4cd7af0802b637428ace",
      "62f9d1b0e19c4073b6bdf0d62b9819fe",
      "4bc2f09d85924af99eb42c779ac86df5",
      "a76b293a22714815adde97160c144abf",
      "fa310233f1a44579a83c45f9ca9aff2a",
      "a7b17d72251043c18f47e7fb512e1530",
      "cea705cfe3a4400b8e891f0ab2d603f0",
      "ed1c93f3950c44519c11689e84f8c5a3",
      "b9f61f8445734c4fb0786444ae90f3ff",
      "f8c977fe374246c08e5b69b31dfbef98",
      "1f955eaf6d334fe0b4316f3ee72609ec",
      "48a935e70c904572ba0d1cd921aa5887",
      "c2744b6f05484ae58ded3ed447f6bb50",
      "62eefa434aad4fa39eefd619d959c265",
      "bf1282d014744c6c9f9a95b506dc6f18",
      "31f3dc8a3fa242e79c896126e976b178",
      "fde2dff8c3db4e5b89332ffa439d1a55",
      "3d721ee7b6494ea798714df3e2cc5809",
      "bb0132a22ef34cc8a2a6310a0d1d664a",
      "ced6160e0eee43f1bb6ba6a50d9dc450",
      "e1f54dc36b6046698fb852a596734d0e",
      "d7b46f75b22745e1b9ef25c9a2dd8f80",
      "9118428362354f3eb9d26a8878f97f38",
      "8a13a84dfa5742bc8562d24f1c177877",
      "8b912a6f51524a8f8c99458e644dd2e4",
      "28b266f8ed9343eda613a0d739d3c4b5",
      "ca9acfc849504306bf5c82d977cdb203",
      "310ff50dbe6c4c7c8f0b7017f73871f8",
      "81435026d7084c3b90737a1d2fd1882c",
      "46b240ad457647b7a750cd98b9ed1070",
      "e7fac8e5196c4043973a93210a61e738",
      "fd44f7491c3f4e409eefe7308fd848f0",
      "92deaff487134f6eb913867058a5c797",
      "33dc6377df4543a3ad8a041898a0ff71",
      "1f14a7ceb8dd4acda2c44da9e1219215",
      "81b311e350fc47c780f1fe41b3c1a93c",
      "299b2584c3814e60bfa4fb6127525bf7",
      "49db79ed53114f5a8e8a94739bfb7136",
      "f2c574a7c437463c8509b82248770cdb",
      "fcd4d3ed72f74793b6ea73c706c4066f",
      "c0597626951e40eb99e9ff80e384ae11",
      "562665dd49f64554942644788f0649f5",
      "a646dcc192604686a221b50ff0e8aba6",
      "a091813d0d4b42dfa1016ab9a2bafcf5",
      "d06a3374b16e4f04948070e758551581",
      "ef818ad967874d8da11979eb8cef632d",
      "5e5d8c84e78e47c3956037553e506005",
      "65b4b1d9f46c448d9c2ab39448cd5a99",
      "12f493e4e17b4768bb6a6bcda5ee8850",
      "71193dc37fec48a98b6c60e669b0ecb2",
      "485b8a1193b448e1b2fee05c2ce642fa",
      "8f91f5fc48a5410dab6b4ea4a389b335",
      "1fdb4dd84fec4f799e36c66a0a9d1044",
      "1e3ec4bd9b754f219c7ed57d55d00ebf",
      "2c265c2760bd484cad8784eb0b74bc5f",
      "d827270dbb014b47bb538bc8905c32f6",
      "0a617297a5c9434490bb73c444220955",
      "55c4e96c81a846c8ba2e075b3786885e",
      "98f02e234c8748729032097b5fc8d07d",
      "4fa034082b094f2f9d460518b359796e",
      "ba14fb8693344cb3afa19f0c4a25f4e3",
      "33616806848146f6a25698fedecc5320",
      "872ae919f9214ddf85b4f710350ce45e",
      "7c5450ed06e740209765c03778ffcc4c",
      "bca969ed1b024455a463505f9d25e39e",
      "8c0973b803a54079bb83e0f01ef48309",
      "2d69d276fa5e46fcb93b2cfb992def99",
      "c19662f504884ffb8c651fb3e268b717",
      "60db24acc51e4f7595ab902381278b8e",
      "70074be2895e49ccb1fa985f8f63abad",
      "04d11106706247f5aaeb812bdf81673c",
      "8ffa6d3fa2f8490d966e1111cff659bd",
      "af5ef9985323438cb927bf6905afeccf",
      "8f39a16155e74dcf9932af70f1122593",
      "b9c4c4ff518d44deb2ae026128015d97",
      "cb001272db2448c0b2859f16d6a3d131",
      "56803659e33d406d995c5e8f3a136738",
      "9302c721191b46658de785dfb881f47e",
      "a4e72e810b244ea0a686ab5b75b39ae9",
      "dcf1afa8d01542fd9a47375e4722d207",
      "312729350f9f4dad977235f288e38648",
      "0f4c2c42fc354f02a95d719ff2d4ffb4",
      "e3b5e474b6ed47169b6e076995666728",
      "e19c6cbe54d049bea107e5d11b9fbc53",
      "63e7c506488b41c09cf4a28604088bcb",
      "ef2b23992c8047cd87645380e090f07a",
      "d68da06e6d0f49a491b31efe99e61347",
      "907ffbf291654460a85a9f0f858d2898",
      "cddab2adf7a1464ba8c280ce22079ea5",
      "be04cd3ce06f446e9a144ab7312f2742",
      "1aaeacf04a794dd09918edcef48fc9dd",
      "1a035759fbcb4cccbede551861ec8bf0",
      "7191fab9a9ce403d80cc94d5ca917997",
      "2de132f700a340ea836d6f9856b8bc37",
      "099cc3cfd9a746fca3a6fe5c675c1563",
      "68715d33b3334e69b5c31d8015f10314",
      "713ea3b40eb940d195ef242bee7383c8",
      "b848ca374ca54c49a56aeab2265f7e0b",
      "7e514e95e6264873a03b8eb246ed7087",
      "6bf53d1035264acbb79b462c3c935f66",
      "c99668842fa5420d9a9f96adcd689d85",
      "fa492466ea2a40bcb45d97d9d5d905f5",
      "5bbd8a74b13d44df8cc778b12e4a8dc6",
      "53e7b6b0241f41a89fe4971d33dbf6e8",
      "aeb75ad226624f93bff3f04dbe95ae87",
      "8dc3bb04a6134878aa1f5204ae92484d",
      "296763daef4c4cba8cc997f62f3ddf41"
     ]
    },
    "collapsed": true,
    "id": "cuCCJNwDAbxp",
    "outputId": "2d910aa0-f89e-4c6b-b05a-7d23024e4b5d"
   },
   "outputs": [],
   "source": [
    "# === Convert profiles to LangChain documents ===\n",
    "docs = [Document(page_content=p['text'], metadata={'UserID': p['UserID']}) for p in user_profiles]\n",
    "\n",
    "# === Embed profiles using MiniLM and store in FAISS ===\n",
    "embedding_model = HuggingFaceEmbeddings(model_name='all-MiniLM-L6-v2')\n",
    "vectorstore = FAISS.from_documents(docs, embedding_model)\n",
    "\n",
    "# === Create retriever and chain ===\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
    "rag_chain = RetrievalQA.from_chain_type(llm=llm, retriever=retriever, chain_type=\"stuff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "fyDfSQ4HA5VQ"
   },
   "outputs": [],
   "source": [
    "# === Stratified Sampling and Random Shuffle ===\n",
    "# Sample 50 users total: 25 addicted and 25 not addicted (adjust as needed)\n",
    "# Query loop with optimized prompt and strict logic for LLM prediction & reasoning\n",
    "n_per_class = 25\n",
    "sampled_df = summary_df.groupby('is_addicted', group_keys=False).apply(\n",
    "    lambda x: x.sample(n=n_per_class, random_state=SEED)\n",
    ").reset_index(drop=True)\n",
    "\n",
    "# Generate new user profiles just for this sample\n",
    "stratified_user_profiles = []\n",
    "user_ids = sampled_df['UserID'].values\n",
    "\n",
    "for _, row in sampled_df.iterrows():\n",
    "    user_id = row['UserID']\n",
    "    features = [f\"{col.replace('_', ' ')} is {row[col]}\" for col in columns_to_include if col in row]\n",
    "    label = f\"The user is {'addicted' if row['is_addicted'] == 1 else 'not addicted'}.\"\n",
    "    text = f\"User {user_id} profile: \" + ', '.join(features) + f\". {label}\"\n",
    "    stratified_user_profiles.append({'UserID': user_id, 'text': text})\n",
    "\n",
    "# Shuffle the stratified list (in-place)\n",
    "random.seed(SEED)\n",
    "random.shuffle(stratified_user_profiles)\n",
    "\n",
    "# === RAG Query Loop ===\n",
    "results = []\n",
    "\n",
    "for profile in stratified_user_profiles:\n",
    "    full_prompt = profile['text'] + (\n",
    "        \"\\n\\nQUESTION: Based on the behavioral profile and SHAP explanations above, \"\n",
    "        \"does this user show signs of online gambling addiction?\\n\"\n",
    "        \"Answer 'Yes' or 'No' at the start of your response, then briefly explain why.\"\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        response = rag_chain.run(full_prompt)\n",
    "    except Exception as e:\n",
    "        response = f\"Error: {str(e)}\"\n",
    "\n",
    "    true_label = sampled_df.loc[sampled_df['UserID'] == profile['UserID'], 'is_addicted'].values[0]\n",
    "\n",
    "    results.append({\n",
    "        'UserID': profile['UserID'],\n",
    "        'Prompt': full_prompt,\n",
    "        'LLM_Response': response,\n",
    "        'True_Label': true_label\n",
    "    })\n",
    "\n",
    "    time.sleep(1.1)  # Stay under rate limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "qUSvafd89Tlo",
    "outputId": "efde7770-503b-444f-a63d-989d6a97e316"
   },
   "outputs": [],
   "source": [
    "# === Convert LLM response to prediction + extract reasoning ===\n",
    "def extract_prediction(response):\n",
    "    if not isinstance(response, str):\n",
    "        return np.nan\n",
    "    response = response.strip().lower()\n",
    "    if response.startswith(\"yes\"):\n",
    "        return 1\n",
    "    elif response.startswith(\"no\"):\n",
    "        return 0\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "def extract_reasoning(response):\n",
    "    if not isinstance(response, str):\n",
    "        return \"\"\n",
    "    match = pd.Series(response).str.extract(r\"(?i)(?:yes|no)[\\s,:.-]*(.*)\")\n",
    "    return match[0].iloc[0] if match[0].notna().any() else \"\"\n",
    "\n",
    "# Build results DataFrame\n",
    "rag_results_df = pd.DataFrame(results)\n",
    "rag_results_df['LLM_Pred'] = rag_results_df['LLM_Response'].apply(extract_prediction)\n",
    "rag_results_df['LLM_Reasoning'] = rag_results_df['LLM_Response'].apply(extract_reasoning)\n",
    "\n",
    "for resp in rag_results_df['LLM_Response'].head(10):\n",
    "    print(\"👉\", repr(resp.split(\"\\n\")[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5TTnr655A7-u",
    "outputId": "e6ebacc4-c182-4227-977f-ecf58d76899e"
   },
   "outputs": [],
   "source": [
    "# === Filter for valid predictions ===\n",
    "valid_preds = rag_results_df.dropna(subset=['LLM_Pred'])\n",
    "\n",
    "# === Log Skipped Users ===\n",
    "skipped_preds = rag_results_df[rag_results_df['LLM_Pred'].isna()].copy()\n",
    "\n",
    "print(f\"\\n Skipped {len(skipped_preds)} users due to ambiguous or invalid LLM responses.\")\n",
    "print(\"🔍 Here are the first 5 skipped responses:\\n\")\n",
    "\n",
    "for idx, row in skipped_preds.head(5).iterrows():\n",
    "    print(f\"UserID: {row['UserID']}\")\n",
    "    print(f\"LLM Response:\\n{row['LLM_Response']}\\n{'-'*60}\")\n",
    "\n",
    "# === Classification Report + Metrics ===\n",
    "print(\" Classification Report for LLM vs SHAP-Driven Ground Truth:\")\n",
    "print(classification_report(valid_preds['True_Label'], valid_preds['LLM_Pred']))\n",
    "\n",
    "auc_score = roc_auc_score(valid_preds['True_Label'], valid_preds['LLM_Pred'])\n",
    "print(f\" AUC Score: {auc_score:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cBPzIV-r9v1M",
    "outputId": "1d8c9f19-074b-4254-fa83-49c50eafce13"
   },
   "outputs": [],
   "source": [
    "# Number of independent runs\n",
    "N_RUNS = 5\n",
    "SEED_BASE = 42\n",
    "\n",
    "# For collecting metrics\n",
    "all_reports = []\n",
    "all_aucs = []\n",
    "\n",
    "for i in range(N_RUNS):\n",
    "    SEED = SEED_BASE + i  # Use a different seed for stratified sampling\n",
    "\n",
    "    # === Stratified Sampling ===\n",
    "    sampled_df = summary_df.groupby('is_addicted', group_keys=False).apply(\n",
    "        lambda x: x.sample(n=n_per_class, random_state=SEED)\n",
    "    ).reset_index(drop=True)\n",
    "\n",
    "    # === Generate User Profiles ===\n",
    "    stratified_user_profiles = []\n",
    "    for _, row in sampled_df.iterrows():\n",
    "        user_id = row['UserID']\n",
    "        features = [f\"{col.replace('_', ' ')} is {row[col]}\" for col in columns_to_include if col in row]\n",
    "        label = f\"The user is {'addicted' if row['is_addicted'] == 1 else 'not addicted'}.\"\n",
    "        text = f\"User {user_id} profile: \" + ', '.join(features) + f\". {label}\"\n",
    "        stratified_user_profiles.append({'UserID': user_id, 'text': text})\n",
    "\n",
    "    random.seed(SEED)\n",
    "    random.shuffle(stratified_user_profiles)\n",
    "\n",
    "    # === RAG Query Loop ===\n",
    "    results = []\n",
    "    for profile in stratified_user_profiles:\n",
    "        full_prompt = profile['text'] + (\n",
    "            \"\\n\\nQUESTION: Based on the behavioral profile and SHAP explanations above, \"\n",
    "            \"does this user show signs of online gambling addiction?\\n\"\n",
    "            \"Answer 'Yes' or 'No' at the start of your response, then briefly explain why.\"\n",
    "        )\n",
    "\n",
    "        try:\n",
    "            response = rag_chain.run(full_prompt)\n",
    "        except Exception as e:\n",
    "            response = f\"Error: {str(e)}\"\n",
    "\n",
    "        true_label = sampled_df.loc[sampled_df['UserID'] == profile['UserID'], 'is_addicted'].values[0]\n",
    "\n",
    "        results.append({\n",
    "            'UserID': profile['UserID'],\n",
    "            'Prompt': full_prompt,\n",
    "            'LLM_Response': response,\n",
    "            'True_Label': true_label\n",
    "        })\n",
    "\n",
    "        time.sleep(1.1)\n",
    "\n",
    "    # === Prediction + Reasoning Extraction ===\n",
    "    rag_results_df = pd.DataFrame(results)\n",
    "    rag_results_df['LLM_Pred'] = rag_results_df['LLM_Response'].apply(extract_prediction)\n",
    "    rag_results_df['LLM_Reasoning'] = rag_results_df['LLM_Response'].apply(extract_reasoning)\n",
    "\n",
    "    valid_preds = rag_results_df.dropna(subset=['LLM_Pred'])\n",
    "\n",
    "    # === Classification Metrics ===\n",
    "    y_true = valid_preds['True_Label']\n",
    "    y_pred = valid_preds['LLM_Pred']\n",
    "    report = classification_report(y_true, y_pred, output_dict=True)\n",
    "    auc = roc_auc_score(y_true, y_pred)\n",
    "\n",
    "    all_reports.append(report)\n",
    "    all_aucs.append(auc)\n",
    "\n",
    "# === Aggregate and Print Averages ===\n",
    "import numpy as np\n",
    "\n",
    "def avg_metric(metric_name, label):\n",
    "    return np.mean([r[label][metric_name] for r in all_reports])\n",
    "\n",
    "print(\"\\n📊 Averaged Classification Results ({} runs):\".format(N_RUNS))\n",
    "for label in ['0', '1', 'macro avg', 'weighted avg']:\n",
    "    print(f\"\\nLabel {label}:\")\n",
    "    for metric in ['precision', 'recall', 'f1-score']:\n",
    "        mean = avg_metric(metric, label)\n",
    "        std = np.std([r[label][metric] for r in all_reports])\n",
    "        print(f\"  {metric}: {mean:.3f} ± {std:.3f}\")\n",
    "\n",
    "print(f\"\\n Average AUC: {np.mean(all_aucs):.3f} ± {np.std(all_aucs):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "yD6Ma6fYJCNC",
    "outputId": "136eae68-67f7-4d14-dbae-4b3370ec1ae5"
   },
   "outputs": [],
   "source": [
    "print(\"\\n Structured LLM Predictions with Reasoning:\")\n",
    "\n",
    "for _, row in valid_preds.iterrows():\n",
    "    print(f\"UserID: {row['UserID']}\")\n",
    "    print(f\"Prediction: {'Yes' if row['LLM_Pred'] == 1 else 'No'}\")\n",
    "    print(f\"Explanation: {row['LLM_Reasoning']}\\n{'-'*60}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 874
    },
    "id": "6muP1std9HC6",
    "outputId": "ac25ee66-9b27-457f-8bf3-08eca206f025"
   },
   "outputs": [],
   "source": [
    "# === Step 9: Confusion Matrix ===\n",
    "cm = confusion_matrix(valid_preds['True_Label'], valid_preds['LLM_Pred'])\n",
    "\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['Predicted Not Addicted', 'Predicted Addicted'],\n",
    "            yticklabels=['Actual Not Addicted', 'Actual Addicted'])\n",
    "plt.title(f' Confusion Matrix: Valid LLM Predictions vs SHAP Labels ({len(valid_preds)} of {len(rag_results_df)} Users)')\n",
    "plt.xlabel('LLM Prediction')\n",
    "plt.ylabel('Ground Truth Label')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# === Step 10: Visual Summary of Predictions and Reasoning ===\n",
    "summary_table = valid_preds[['UserID', 'LLM_Pred', 'True_Label', 'LLM_Reasoning']].copy()\n",
    "summary_table['LLM_Pred'] = summary_table['LLM_Pred'].map({1: 'Addicted', 0: 'Not Addicted'})\n",
    "summary_table['True_Label'] = summary_table['True_Label'].map({1: 'Addicted', 0: 'Not Addicted'})\n",
    "\n",
    "# Optional: truncate reasoning to make it readable in console\n",
    "summary_table['LLM_Reasoning'] = summary_table['LLM_Reasoning'].str.slice(0, 200)\n",
    "\n",
    "print(\"\\n Class Distribution in Valid Predictions:\")\n",
    "print(valid_preds['True_Label'].value_counts().rename({0: 'Not Addicted', 1: 'Addicted'}))\n",
    "\n",
    "print(f\"\\n LLM Classification & Explanation Summary (First 10 of {len(valid_preds)} Users):\\n\")\n",
    "print(summary_table.head(10).to_string(index=False))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
